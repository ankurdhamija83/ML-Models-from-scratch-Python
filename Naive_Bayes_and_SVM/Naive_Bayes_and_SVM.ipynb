{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes had an accuracy of 0.978494623655914 on the testing set\n",
      "The top 5 indicative words for Naive Bayes are:  ['claim', 'won', 'prize', 'tone', 'urgent!']\n",
      "The optimal SVM radius was 0.1\n",
      "The SVM model had an accuracy of 0.9695340501792115 on the testing set\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import util\n",
    "import svm\n",
    "\n",
    "\n",
    "def get_words(message):\n",
    "    \"\"\"Get the normalized list of words from a message string.\n",
    "\n",
    "    This function should split a message into words, normalize them, and return\n",
    "    the resulting list. For splitting, you should split on spaces. For normalization,\n",
    "    you should convert everything to lowercase.\n",
    "\n",
    "    Note for enterprising students:  There are myriad ways to split sentences for\n",
    "    this algorithm.  For instance, you might want to exclude punctuation (unless\n",
    "    it's organized in an email address format) or exclude numbers (unless they're\n",
    "    organized in a zip code or phone number format).  Clearly this can become quite\n",
    "    complex.  For our purposes, please split using the space character ONLY.  This\n",
    "    is intended to balance your understanding with our ability to autograde the\n",
    "    assignment.  Thanks and have fun with the rest of the assignment!\n",
    "\n",
    "    Args:\n",
    "        message: A string containing an SMS message\n",
    "\n",
    "    Returns:\n",
    "       The list of normalized words from the message.\n",
    "    \"\"\"\n",
    "\n",
    "    # *** START CODE HERE ***\n",
    "    \n",
    "    #Convert to lowercase\n",
    "    message = message.lower()    \n",
    "    \n",
    "    #Split the message based on space delimiter and store values in a list\n",
    "    x = message.split(\" \")\n",
    "    \n",
    "    return x\n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "\n",
    "def create_dictionary(messages):\n",
    "    \"\"\"Create a dictionary mapping words to integer indices.\n",
    "\n",
    "    This function should create a dictionary of word to indices using the provided\n",
    "    training messages. Use get_words to process each message.\n",
    "\n",
    "    Rare words are often not useful for modeling. Please only add words to the dictionary\n",
    "    if they occur in at least *five messages*.\n",
    "\n",
    "    Args:\n",
    "        messages: A list of strings containing SMS messages\n",
    "\n",
    "    Returns:\n",
    "        A python dict mapping words to integers.\n",
    "    \"\"\"\n",
    "\n",
    "    # *** START CODE HERE ***\n",
    "\n",
    "    #Initialize an empty list\n",
    "    word_list = []\n",
    "    \n",
    "    #Loop over all the messages and append the words from each message in a list\n",
    "    for i in range(0, len(messages)):\n",
    "        \n",
    "        #Convert the message string to lowercase and return a list of words \n",
    "        #in the input message string by using space separator\n",
    "        temp_list = get_words(messages[i])\n",
    "        \n",
    "        #Remove duplicate words from the list\n",
    "        temp_list = list(dict.fromkeys(temp_list))\n",
    "        [word_list.append(x) for x in temp_list]\n",
    "        \n",
    "    \n",
    "    #Create a dict which maps frequencies of words in a list\n",
    "    freq = {}\n",
    "    for item in word_list:\n",
    "        if (item in freq):\n",
    "            freq[item] += 1\n",
    "        else:\n",
    "            freq[item] = 1\n",
    "    \n",
    "\n",
    "    #Select only those words which occur in at least 5 messages\n",
    "    result = {key:value for (key, value) in freq.items() if value >= 5}\n",
    "    \n",
    "    return result\n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "\n",
    "def transform_text(messages, word_dictionary):\n",
    "    \"\"\"Transform a list of text messages into a numpy array for further processing.\n",
    "\n",
    "    This function should create a numpy array that contains the number of times each word\n",
    "    of the vocabulary appears in each message.\n",
    "    Each row in the resulting array should correspond to each message\n",
    "    and each column should correspond to *a word of the vocabulary*.\n",
    "\n",
    "    Use the provided word dictionary to map words to column indices. Ignore words that\n",
    "    are not present in the dictionary. Use get_words to get the words for a message.\n",
    "\n",
    "    Args:\n",
    "        messages: A list of strings where each string is an SMS message.\n",
    "        word_dictionary: A python dict mapping words to integers.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array marking the words present in each message.\n",
    "        Where the component (i,j) is the number of occurrences of the\n",
    "        j-th vocabulary word in the i-th message.\n",
    "    \"\"\"\n",
    "    # *** START CODE HERE ***\n",
    "\n",
    "\n",
    "    #Initialize a np.array \n",
    "    word_matrix = np.zeros((len(messages), len(word_dictionary)))\n",
    "    \n",
    "\n",
    "    \n",
    "    #Loop over all the messages and append the words from each message in a list\n",
    "    for i in range(0, len(messages)):\n",
    "        \n",
    "        #Convert the message string to lowercase and return a list of words in the input message string by using space separator\n",
    "        temp_list = get_words(messages[i])\n",
    "         \n",
    "        dict_count = 0\n",
    "        \n",
    "        #Loop over the dictionary\n",
    "        for x, y in word_dictionary.items():\n",
    "            occurrences = temp_list.count(x)\n",
    "            word_matrix[i, dict_count] = occurrences\n",
    "            dict_count += 1\n",
    "    \n",
    "            \n",
    "    return word_matrix\n",
    "    #Row is for each message\n",
    "    #Column is for each word in the dictionary\n",
    "    #Entry i,j describes the frequency of a given word in the message\n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "\n",
    "def fit_naive_bayes_model(matrix, labels):\n",
    "    \"\"\"Fit a naive bayes model.\n",
    "\n",
    "    This function should fit a Naive Bayes model given a training matrix and labels.\n",
    "\n",
    "    The function should return the state of that model.\n",
    "\n",
    "    Feel free to use whatever datatype you wish for the state of the model.\n",
    "\n",
    "    Args:\n",
    "        matrix: A numpy array containing word counts for the training data\n",
    "        labels: The binary (0 or 1) labels for that training data\n",
    "\n",
    "    Returns: The trained model\n",
    "    \"\"\"\n",
    "    \n",
    "    # *** START CODE HERE ***\n",
    "\n",
    "    #Length of the vocabulary\n",
    "    vocab_len = matrix.shape[1]\n",
    "    \n",
    "    #Boolean indexing for categorizing messages based on Labels\n",
    "    mask = labels == 1\n",
    "    \n",
    "    #Fancy indexing to get Spam messages into a separate matrix\n",
    "    spam = matrix[mask,:]\n",
    "    \n",
    "    #Fancy indexing to get Ham messages into a separate matrix\n",
    "    ham = matrix[~mask,:]\n",
    "    \n",
    "    #Function to calculate phi for spam and ham messages\n",
    "    def calc_phi(matrix, vocab_len):\n",
    "        \n",
    "        #This will take the frequency sum of each word across messages\n",
    "        word_total = np.sum(matrix,axis=0)\n",
    "        \n",
    "        #Calculating the numerator\n",
    "        num = (1+word_total)\n",
    "        \n",
    "        #Calculating the denominator\n",
    "        den = vocab_len+np.sum(matrix)\n",
    "        \n",
    "        return np.divide(num, den)\n",
    "    \n",
    "    \n",
    "    phi_k_y1 = calc_phi(spam, vocab_len)\n",
    "    phi_k_y0 = calc_phi(ham, vocab_len)\n",
    "    phi_y = spam.shape[0]/matrix.shape[0]\n",
    "\n",
    "#     print(\"\\n\\n\")  \n",
    "#     print(\"This is phi_k_y1: \", phi_k_y1)\n",
    "#     print(\"This is phi_k_y0: \", phi_k_y0)\n",
    "#     print(\"This is phi_y: \", phi_y)\n",
    "#     print(\"\\n\\n\")  \n",
    "    \n",
    "    return phi_k_y0, phi_k_y1, phi_y\n",
    "    \n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "\n",
    "def predict_from_naive_bayes_model(model, matrix):\n",
    "    \"\"\"Use a Naive Bayes model to compute predictions for a target matrix.\n",
    "\n",
    "    This function should be able to predict on the models that fit_naive_bayes_model\n",
    "    outputs.\n",
    "\n",
    "    Args:\n",
    "        model: A trained model from fit_naive_bayes_model\n",
    "        matrix: A numpy array containing word counts\n",
    "\n",
    "    Returns: A numpy array containing the predictions from the model\n",
    "    \"\"\"\n",
    "    # *** START CODE HERE ***\n",
    "    \n",
    "    output = np.zeros(matrix.shape[0])\n",
    "    \n",
    "#     print(\"This is matrix shape: \", matrix.shape)\n",
    "    #558, 1717\n",
    "    \n",
    "    #This function returns the log probability for each given input model (spam or ham)\n",
    "    def calc_prob(matrix, model):\n",
    "        \n",
    "        log_prob = np.multiply(matrix, np.log(model))\n",
    "        \n",
    "        #Take the sum of logs\n",
    "        return np.sum(log_prob, axis = 1)\n",
    "    \n",
    "    \n",
    "    phi_notspam = model[0]\n",
    "    phi_spam = model[1]\n",
    "    \n",
    "    \n",
    "    #We get the log probability for both p(y=0) and p(y=1)\n",
    "    num = calc_prob(matrix, phi_notspam)\n",
    "    den = calc_prob(matrix, phi_spam)\n",
    "    \n",
    "    ratio_calc = num - den + np.log(1-model[2]) - np.log(model[2])\n",
    "    ratio_calc = np.exp(ratio_calc)\n",
    "    \n",
    "    final_prob = 1/(1+ratio_calc)\n",
    "    \n",
    "    output[final_prob > 0.5] = 1\n",
    "    \n",
    "    return output\n",
    "    \n",
    "    \n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "\n",
    "def get_top_five_naive_bayes_words(model, dictionary):\n",
    "    \"\"\"Compute the top five words that are most indicative of the spam (i.e positive) class.\n",
    "\n",
    "    Ues the metric given in part-c as a measure of how indicative a word is.\n",
    "    Return the words in sorted form, with the most indicative word first.\n",
    "\n",
    "    Args:\n",
    "        model: The Naive Bayes model returned from fit_naive_bayes_model\n",
    "        dictionary: A mapping of word to integer ids\n",
    "\n",
    "    Returns: A list of the top five most indicative words in sorted order with the most indicative first\n",
    "    \"\"\"\n",
    "    # *** START CODE HERE ***\n",
    "    \n",
    "        \n",
    "    #Calculate the result as per the formula in PS1(c)\n",
    "    result = np.log(model[1]) - np.log(model[0])\n",
    "    \n",
    "    #Get the index location of top5_words\n",
    "    top5_index = result.argsort()[-5:][::-1]\n",
    "    \n",
    "    #Array to store the final 5 words\n",
    "    final = []\n",
    "    \n",
    "    #Get the words from dictionary in an arr to match their index\n",
    "    word_arr = []\n",
    "    \n",
    "    for key, values in dictionary.items():\n",
    "        word_arr.append(key) \n",
    "    \n",
    "    for i in top5_index:\n",
    "        final.append(word_arr[i])\n",
    "    \n",
    "    return final\n",
    "    \n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "\n",
    "def compute_best_svm_radius(train_matrix, train_labels, val_matrix, val_labels, radius_to_consider):\n",
    "    \"\"\"Compute the optimal SVM radius using the provided training and evaluation datasets.\n",
    "\n",
    "    You should only consider radius values within the radius_to_consider list.\n",
    "    You should use accuracy as a metric for comparing the different radius values.\n",
    "\n",
    "    Args:\n",
    "        train_matrix: The word counts for the training data\n",
    "        train_labels: The spma or not spam labels for the training data\n",
    "        val_matrix: The word counts for the validation data\n",
    "        val_labels: The spam or not spam labels for the validation data\n",
    "        radius_to_consider: The radius values to consider\n",
    "\n",
    "    Returns:\n",
    "        The best radius which maximizes SVM accuracy.\n",
    "    \"\"\"\n",
    "    # *** START CODE HERE ***\n",
    "    \n",
    "    \n",
    "    svm_pred_list = list(map(lambda sel_radius: svm.train_and_predict_svm(train_matrix, train_labels, val_matrix, sel_radius), radius_to_consider))\n",
    "    \n",
    "\n",
    "    svm_accuracy_list = list(map(lambda svm_pred: np.mean(svm_pred == val_labels), svm_pred_list))\n",
    "    \n",
    "    max_value = max(svm_accuracy_list)\n",
    "\n",
    "\n",
    "    max_index = svm_accuracy_list.index(max_value)\n",
    "    \n",
    "    return radius_to_consider[max_index]\n",
    "    \n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_messages, train_labels = util.load_spam_dataset('spam_train.tsv')\n",
    "    val_messages, val_labels = util.load_spam_dataset('spam_val.tsv')\n",
    "    test_messages, test_labels = util.load_spam_dataset('spam_test.tsv')\n",
    "\n",
    "    dictionary = create_dictionary(train_messages)\n",
    "\n",
    "    util.write_json('spam_dictionary_(soln)', dictionary)\n",
    "\n",
    "    train_matrix = transform_text(train_messages, dictionary)\n",
    "\n",
    "    np.savetxt('spam_sample_train_matrix_(soln)', train_matrix[:100,:])\n",
    "\n",
    "    val_matrix = transform_text(val_messages, dictionary)\n",
    "    test_matrix = transform_text(test_messages, dictionary)\n",
    "\n",
    "    naive_bayes_model = fit_naive_bayes_model(train_matrix, train_labels)\n",
    "\n",
    "    naive_bayes_predictions = predict_from_naive_bayes_model(naive_bayes_model, test_matrix)\n",
    "\n",
    "    np.savetxt('spam_naive_bayes_predictions_(soln)', naive_bayes_predictions)\n",
    "\n",
    "    naive_bayes_accuracy = np.mean(naive_bayes_predictions == test_labels)\n",
    "\n",
    "    print('Naive Bayes had an accuracy of {} on the testing set'.format(naive_bayes_accuracy))\n",
    "\n",
    "    top_5_words = get_top_five_naive_bayes_words(naive_bayes_model, dictionary)\n",
    "\n",
    "    print('The top 5 indicative words for Naive Bayes are: ', top_5_words)\n",
    "\n",
    "    util.write_json('spam_top_indicative_words_(soln)', top_5_words)\n",
    "\n",
    "    optimal_radius = compute_best_svm_radius(train_matrix, train_labels, val_matrix, val_labels, [0.01, 0.1, 1, 10])\n",
    "\n",
    "    util.write_json('spam_optimal_radius_(soln)', optimal_radius)\n",
    "\n",
    "    print('The optimal SVM radius was {}'.format(optimal_radius))\n",
    "\n",
    "    svm_predictions = svm.train_and_predict_svm(train_matrix, train_labels, test_matrix, optimal_radius)\n",
    "\n",
    "    svm_accuracy = np.mean(svm_predictions == test_labels)\n",
    "\n",
    "    print('The SVM model had an accuracy of {} on the testing set'.format(svm_accuracy, optimal_radius))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
